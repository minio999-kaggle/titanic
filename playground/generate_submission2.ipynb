{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8115bd13-af7c-4d04-aeda-581a7ff499d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StackingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 134>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m X_train, X_test \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[train_index], X\u001b[38;5;241m.\u001b[39mloc[test_index]\n\u001b[1;32m    136\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mloc[train_index], y\u001b[38;5;241m.\u001b[39mloc[test_index]\n\u001b[0;32m--> 138\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mStackingClassifier\u001b[49m(\n\u001b[1;32m    139\u001b[0m estimators\u001b[38;5;241m=\u001b[39mestimators, final_estimator\u001b[38;5;241m=\u001b[39mRandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39mN_ESTIMATORS, bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    140\u001b[0m                             min_samples_leaf\u001b[38;5;241m=\u001b[39mMIN_SAMPLES_LEAF,\n\u001b[1;32m    141\u001b[0m                             min_samples_split\u001b[38;5;241m=\u001b[39mMIN_SAMPLE_SPLIT, random_state\u001b[38;5;241m=\u001b[39mRANDOM_STATE)\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    145\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m    146\u001b[0m y_predict \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StackingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "MIN_SAMPLE_SPLIT=4\n",
    "MIN_SAMPLES_LEAF=5\n",
    "N_ESTIMATORS=100\n",
    "N_SPLITS = 5\n",
    "USELESS_FEATURES = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\",\n",
    "                    \"Parch\", \"SibSp\", 'Embarked', 'Fare']\n",
    "PATH = '../data/train.csv'\n",
    "df_raw = pd.read_csv(PATH)\n",
    "\n",
    "\n",
    "def impute_age(df, value):\n",
    "    '''\n",
    "    Replaces Nulls in column \"Age\" of a dataframe with the passed value\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pandas.DataFrame): DataFrame on which to operate\n",
    "        value (float): Value used for imputation\n",
    "    Returns:\n",
    "        pandas.DataFrame\n",
    "    '''\n",
    "\n",
    "    df['Age'] = df[\"Age\"].fillna(value)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_sex(df):\n",
    "    '''\n",
    "    Replacing sex in column \"Sex\" of a dataframe to 1 if it's male and 0 if it's female\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pandas.DataFrame): Dataframe on which to operate\n",
    "    Returns:\n",
    "        pandas.DataFrame\n",
    "    '''\n",
    "\n",
    "    df['is_male'] = 0\n",
    "    df.loc[df['Sex'] == 'male', 'is_male'] = 1\n",
    "    df = df.drop(columns=['Sex'])\n",
    "    return df\n",
    "\n",
    "def count_relatives_on_board(df):\n",
    "    '''\n",
    "    Counting Relatives on board based of sibsp and parch columns\n",
    "\n",
    "    Paramters:\n",
    "        dataframe (pandas.DataFrame): Dataframe on which to operate\n",
    "    Retruns:\n",
    "        pandas.DataFrame\n",
    "    '''\n",
    "\n",
    "    df[\"RelativesOnboard\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
    "    return df\n",
    "\n",
    "def set_title(df):\n",
    "    '''\n",
    "    Changing name titles to cryptonims\n",
    "\n",
    "    Paramters:\n",
    "        dataframe (pandas.DataFrame): Dataframe on which to operate\n",
    "    Retruns:\n",
    "        pandas.DataFrame\n",
    "    '''\n",
    "\n",
    "    mapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n",
    "      'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\n",
    "\n",
    "    df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "    df.replace({'Title': mapping}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def title_encode(df):\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Title'] = label_encoder.fit_transform(df['Title'])\n",
    "    return df\n",
    "\n",
    "def scaling_values(df):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df)\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    scaled_data = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "    scaled_data['Survived'] = df['Survived']\n",
    "    return scaled_data\n",
    "\n",
    "def transform_data(df, mean_age_value):\n",
    "    '''\n",
    "    Applying data cleaning functions to data sets\n",
    "\n",
    "    Paramters:\n",
    "        dataframe (pandas.DataFrame): Dataframe on which to operate\n",
    "        mean_age (float): Mean age of training data set\n",
    "    Retruns:\n",
    "        pandas.DataFrame\n",
    "    '''\n",
    "    df = set_title(df)\n",
    "    df = count_relatives_on_board(df)\n",
    "    df = impute_age(df, mean_age_value)\n",
    "    df = convert_sex(df)\n",
    "    df = title_encode(df)\n",
    "    df.drop(USELESS_FEATURES, inplace=True,axis=1)\n",
    "    df = scaling_values(df)\n",
    "    return df\n",
    "\n",
    "estimators = [\n",
    "    ('knn_clf', KNeighborsClassifier()),\n",
    "    ('gb_clf', GradientBoostingClassifier()),\n",
    "    ('ada_clf', AdaBoostClassifier()),\n",
    "]\n",
    "\n",
    "LABEL = 'Survived'\n",
    "mean_age = df_raw['Age'].mean()\n",
    "df = transform_data(df_raw, mean_age)\n",
    "X = df\n",
    "X = X.drop('Survived', axis=1)\n",
    "y = df['Survived']\n",
    "\n",
    "k_fold = KFold(\n",
    "    n_splits=N_SPLITS,\n",
    "    shuffle=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in k_fold.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "    clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=RandomForestClassifier(n_estimators=N_ESTIMATORS, bootstrap=True, criterion='entropy',\n",
    "                                min_samples_leaf=MIN_SAMPLES_LEAF,\n",
    "                                min_samples_split=MIN_SAMPLE_SPLIT, random_state=RANDOM_STATE)\n",
    "    )\n",
    "\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predict = clf.predict(X_test)\n",
    "\n",
    "    acc_score = round(accuracy_score(y_test, y_predict),3)\n",
    "\n",
    "    print(acc_score)\n",
    "\n",
    "    scores.append(acc_score)\n",
    "\n",
    "print()\n",
    "print(\"Average:\", round(100*np.mean(scores), 1), \"%\")\n",
    "print(\"Std:\", round(100*np.std(scores), 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8131c94b-6a32-4cd8-b2bd-cd7c18675ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.272590361445783"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv('../data/test.csv')\n",
    "test_ids = X_test[\"PassengerId\"]\n",
    "mean_age = X_test['Age'].mean()\n",
    "mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d67f06f-015d-47e2-b64e-457937a538f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = transform_data(X_test, mean_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30a88e3b-a400-407c-979a-48ca9c3bf12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = clf.predict(X_test)\n",
    "y_test = y_test.astype(int)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f92054d3-3f8a-4c0d-8310-54043ba6f60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame({'PassengerId': test_ids, 'Survived': y_test})\n",
    "output.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6fb42-6b27-48b4-94d0-2ae6e9c223ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559c8f4-0c5a-4183-8d7f-25729af3bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122c80b-b69d-49d3-b22c-a45c4dcea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Fare'] = X_test['Fare'].fillna(35.627188)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fca85d-f3ca-4133-975c-b38033364d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
